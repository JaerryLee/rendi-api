<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Clova Speech STT + AI Pipeline 테스트</title>
  <style>
    body { font-family: Arial; padding: 2rem; background: #fafafa; }
    h1 { color: #333; }
    button { padding: .5rem 1rem; margin-right: 1rem; }
    #status { margin-bottom: 1rem; }
    #log, #json {
      white-space: pre-wrap;
      background: #fff;
      padding: 1rem;
      border: 1px solid #ddd;
      height: 200px;
      overflow-y: scroll;
      margin-top: .5rem;
    }
    #json { background: #222; color: #eee; border-color: #333; }
    .interim { color: #666; }
    .final   { color: #228822; font-weight: bold; }
    .error   { color: #cc2222; }
  </style>
</head>
<body>
  <h1>Clova Speech STT + AI Pipeline 테스트</h1>
  <button id="startBtn">Start Streaming</button>
  <button id="stopBtn" disabled>Stop Streaming</button>
  <div id="status">Status: 🚫 Not connected</div>

  <h2>Combined Transcripts & AI Response</h2>
  <div id="log"></div>

  <h2>Raw JSON from Backend</h2>
  <div id="json"></div>

  <script>
    const WS_URL        = 'wss://api.rendi.online/ws/speech';
    const SAMPLE_RATE   = 16000;
    const FRAME_MS      = 20;
    const FRAME_SAMPLES = SAMPLE_RATE * FRAME_MS / 1000; // 320 samples

    let audioCtx, workletNode, ws, stream;
    const statusEl = document.getElementById('status');
    const logEl    = document.getElementById('log');
    const jsonEl   = document.getElementById('json');
    const startBtn = document.getElementById('startBtn');
    const stopBtn  = document.getElementById('stopBtn');

    function setStatus(txt, cls) {
      statusEl.textContent = 'Status: ' + txt;
      statusEl.className = cls || '';
    }

    startBtn.onclick = async () => {
      logEl.innerHTML  = '';
      jsonEl.innerHTML = '';
      setStatus('connecting…');

      // 1) WebSocket open
      ws = new WebSocket(WS_URL);
      ws.binaryType = 'arraybuffer';

      ws.onopen = () => {
        setStatus('🟢 Connected');
        startBtn.disabled = true;
        stopBtn.disabled  = false;
      };

      ws.onmessage = ev => {
        const msg = JSON.parse(ev.data);

        // Combined log: 발화 + AI 응답 정보를 한 번에 표시
        const div = document.createElement('div');
        div.className = 'final';
        div.innerHTML = `
          <strong>[${msg.message.role}] ${msg.message.content}</strong><br/>
          scores: ${JSON.stringify(msg.scores)}<br/>
          memory: ${JSON.stringify(msg.partner_memory)}<br/>
          analysis: ${JSON.stringify(msg.analysis)}<br/>
          advice: ${JSON.stringify(msg.advice_metadatas)}
        `;
        logEl.appendChild(div);
        logEl.scrollTop = logEl.scrollHeight;

        // Raw JSON
        const pre = document.createElement('pre');
        pre.textContent = JSON.stringify(msg, null, 2);
        jsonEl.appendChild(pre);
        jsonEl.scrollTop = jsonEl.scrollHeight;
      };

      ws.onerror = () => setStatus('❌ WebSocket Error', 'error');
      ws.onclose = () => {
        setStatus('🚫 Disconnected');
        startBtn.disabled = false;
        stopBtn.disabled  = true;
      };

      // 2) 마이크 권한 요청 & AudioWorklet 준비
      try {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      } catch {
        return setStatus('❌ 마이크 권한 거부', 'error');
      }

      audioCtx = new AudioContext({ sampleRate: SAMPLE_RATE });
      await audioCtx.audioWorklet.addModule(URL.createObjectURL(new Blob([`
        class PCMProcessor extends AudioWorkletProcessor {
          constructor() {
            super();
            this.buf = [];
          }
          process(inputs) {
            const in0 = inputs[0][0];
            if (!in0) return true;
            this.buf.push(...in0);
            while (this.buf.length >= ${FRAME_SAMPLES}) {
              this.port.postMessage(this.buf.splice(0, ${FRAME_SAMPLES}));
            }
            return true;
          }
        }
        registerProcessor('pcm-processor', PCMProcessor);
      `], { type: 'application/javascript' })));

      // 3) WorkletNode → WebSocket 전송
      workletNode = new AudioWorkletNode(audioCtx, 'pcm-processor');
      workletNode.port.onmessage = e => {
        if (ws.readyState === WebSocket.OPEN) {
          const float32 = e.data;
          const pcm16   = new Int16Array(float32.length);
          for (let i = 0; i < float32.length; i++) {
            const s = Math.max(-1, Math.min(1, float32[i]));
            pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
          }
          ws.send(pcm16.buffer);
        }
      };

      // 4) Audio routing
      const src = audioCtx.createMediaStreamSource(stream);
      src.connect(workletNode).connect(audioCtx.destination);
    };

    stopBtn.onclick = () => {
      workletNode?.disconnect();
      audioCtx?.close();
      stream?.getTracks().forEach(t => t.stop());
      ws?.close();
    };
  </script>
</body>
</html>
